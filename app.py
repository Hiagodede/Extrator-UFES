import streamlit as st
import google.generativeai as genai
import pandas as pd
import json
import io

# --- CONFIGURA√á√ÉO E SEGURAN√áA ---
st.set_page_config(page_title="Extrator UFES", layout="wide")

# Recupera a chave dos Segredos do Streamlit (Ambiente de Produ√ß√£o)
# Ou usa uma vari√°vel local se estiver rodando na sua m√°quina (fallback)
api_key = st.secrets.get("GOOGLE_API_KEY")

if not api_key:
    st.error("Erro Cr√≠tico: Chave de API n√£o configurada nos secrets.")
    st.stop()

genai.configure(api_key=api_key)

# --- ENGINE DE EXTRA√á√ÉO ---
def extract_data_from_pdf(file_bytes):
    model = genai.GenerativeModel(
        "gemini-1.5-flash",
        generation_config={"response_mime_type": "application/json"}
    )

    # Prompt System Engineering:
    # Instru√ß√£o expl√≠cita para limpar a sujeira do layout do SIPAC/UFES
    prompt = """
    Voc√™ √© um parser de dados especialista em relat√≥rios governamentais (SIPAC).
    Analise o PDF anexo. O layout visual √© tabular mas inconsistente (quebras de linha dentro da c√©lula).
    
    OBJETIVO: Extrair metadados de envio de documentos.
    
    PADR√ÉO DE DADOS ESPERADO NA C√âLULA:
    Muitas vezes o 'C√≥digo de Rastreio' (termina em BR) e o 'Processo' (formato N/ANO-DV) est√£o na mesma "coluna visual" mas em linhas diferentes. Separe-os.
    
    SA√çDA OBRIGAT√ìRIA (JSON Array):
    [
      {
        "rastreio": "C√≥digo dos correios (ex: AL989685414BR) ou null",
        "processo": "N√∫mero do processo (ex: 004094/2025-73) ou null",
        "data_envio": "Data no formato DD/MM/AAAA",
        "hora_envio": "Hora no formato HH:MM:SS",
        "destino": "Nome completo do setor de destino (ex: PPGCTA/CCAE...)",
        "documento_tipo": "Tipo do documento se houver (ex: Of√≠cio, Correspond√™ncia)"
      }
    ]
    
    REGRAS DE HIGIENIZA√á√ÉO:
    1. Ignore cabe√ßalhos de p√°gina, rodap√©s, "UFES", "P√°gina X".
    2. Se uma linha tiver dados quebrados, una o contexto baseando-se na data/hora.
    3. Retorne apenas o JSON cru, sem markdown.
    """

    try:
        response = model.generate_content(
            [prompt, {"mime_type": "application/pdf", "data": file_bytes}]
        )
        return json.loads(response.text)
    except Exception as e:
        st.error(f"Falha na infer√™ncia da IA: {e}")
        return []

# --- INTERFACE (FRONT-END) ---
st.title("üìÑ Extrator de Protocolo UFES")
st.markdown("**Instru√ß√µes:** Fa√ßa upload do PDF gerado pelo sistema. A IA vai normalizar a tabela.")

uploaded_file = st.file_uploader("Arraste o PDF aqui", type=["pdf"])

if uploaded_file:
    with st.spinner('Processando documento via Gemini 1.5 Flash...'):
        bytes_data = uploaded_file.getvalue()
        data = extract_data_from_pdf(bytes_data)
        
        if data:
            df = pd.read_json(json.dumps(data))
            
            # Exibi√ß√£o de M√©tricas
            col1, col2 = st.columns(2)
            col1.metric("Registros Extra√≠dos", len(df))
            col1.info("Verifique se o total bate com o final do PDF.")
            
            # Preview da Tabela
            st.dataframe(df, use_container_width=True)
            
            # Engine de Download (Excel Nativo)
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                df.to_excel(writer, index=False, sheet_name='Extracao_IA')
                # Ajuste autom√°tico de colunas (perfumaria t√©cnica)
                worksheet = writer.sheets['Extracao_IA']
                for i, col in enumerate(df.columns):
                    width = max(df[col].astype(str).map(len).max(), len(col))
                    worksheet.set_column(i, i, width + 2)
            
            st.download_button(
                label="üì• Baixar Excel Formatado",
                data=output.getvalue(),
                file_name="Relatorio_Processado.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                type="primary"
            )
        else:
            st.warning("Nenhum dado estruturado foi encontrado.")